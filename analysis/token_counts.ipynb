{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2692aa5b",
   "metadata": {},
   "source": [
    "# Prompt token/word/char counts\n",
    "\n",
    "Load the first prompt from several prompt JSON files and report:\n",
    "- n characters\n",
    "- n words (whitespace split)\n",
    "- n tokens (simple non-whitespace tokenization using regex)\n",
    "\n",
    "The notebook auto-discovers files in the `prompts/` directory and prints which files were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77740888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f05c8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt files used (in order):\n",
      " - /Users/rsalvi/Desktop/mccviahat/prompts/training_n.json\n",
      " - /Users/rsalvi/Desktop/mccviahat/prompts/training_e.json\n",
      " - /Users/rsalvi/Desktop/mccviahat/prompts/test_n.json\n",
      " - /Users/rsalvi/Desktop/mccviahat/prompts/test_e.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>method</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/rsalvi/Desktop/mccviahat/prompts/traini...</td>\n",
       "      <td>direct</td>\n",
       "      <td>9612</td>\n",
       "      <td>1548</td>\n",
       "      <td>2155</td>\n",
       "      <td>Begin the repair by carefully opening the door...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/rsalvi/Desktop/mccviahat/prompts/traini...</td>\n",
       "      <td>direct</td>\n",
       "      <td>7944</td>\n",
       "      <td>1354</td>\n",
       "      <td>2166</td>\n",
       "      <td>It's around noon on a hot day in April.&nbsp;&nbsp;You a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/rsalvi/Desktop/mccviahat/prompts/test_n...</td>\n",
       "      <td>direct</td>\n",
       "      <td>8891</td>\n",
       "      <td>1447</td>\n",
       "      <td>2141</td>\n",
       "      <td>On a completely ordinary Thursday morning, jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/rsalvi/Desktop/mccviahat/prompts/test_e...</td>\n",
       "      <td>direct</td>\n",
       "      <td>7405</td>\n",
       "      <td>1213</td>\n",
       "      <td>2156</td>\n",
       "      <td>You're alone in a thick, foggy forest as night...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  method  n_chars  \\\n",
       "1  /Users/rsalvi/Desktop/mccviahat/prompts/traini...  direct     9612   \n",
       "2  /Users/rsalvi/Desktop/mccviahat/prompts/traini...  direct     7944   \n",
       "3  /Users/rsalvi/Desktop/mccviahat/prompts/test_n...  direct     8891   \n",
       "4  /Users/rsalvi/Desktop/mccviahat/prompts/test_e...  direct     7405   \n",
       "\n",
       "   n_words  n_tokens                                            preview  \n",
       "1     1548      2155  Begin the repair by carefully opening the door...  \n",
       "2     1354      2166  It's around noon on a hot day in April.  You a...  \n",
       "3     1447      2141  On a completely ordinary Thursday morning, jus...  \n",
       "4     1213      2156  You're alone in a thick, foggy forest as night...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved counts to:\n",
      " - /Users/rsalvi/Desktop/mccviahat/analysis/token_counts.csv  (250 bytes)\n",
      " - /Users/rsalvi/Desktop/mccviahat/analysis/analysis/token_counts.csv  (250 bytes)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "# --- Tokenizer (LLaMA-family) ---\n",
    "\n",
    "# If you're using a different LLaMA 7B variant, swap this string to the matching tokenizer repo.\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"LLaMA-style token count via HF tokenizer (subword tokens, not whitespace runs).\"\"\"\n",
    "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "def _find_first_string_in_obj(obj):\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    if isinstance(obj, list) and obj:\n",
    "        for v in obj:\n",
    "            s = _find_first_string_in_obj(v)\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(obj, dict) and obj:\n",
    "        for k in ('instructions', 'instruction', 'prompt', 'text', 'content', 'body', 'question'):\n",
    "            if k in obj and isinstance(obj[k], str) and obj[k].strip():\n",
    "                return obj[k]\n",
    "        for v in obj.values():\n",
    "            s = _find_first_string_in_obj(v)\n",
    "            if s:\n",
    "                return s\n",
    "    return None\n",
    "\n",
    "def load_first_prompt(path: Path) -> tuple[str, str]:\n",
    "    if not path.exists():\n",
    "        return ('', 'missing')\n",
    "    raw = path.read_text(encoding='utf-8')\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except Exception:\n",
    "        return (raw, 'raw')\n",
    "\n",
    "    if isinstance(data, list) and len(data) > 0:\n",
    "        first = data[0]\n",
    "        s = _find_first_string_in_obj(first)\n",
    "        if s:\n",
    "            return (s, 'direct')\n",
    "        s = _find_first_string_in_obj(data)\n",
    "        if s:\n",
    "            return (s, 'direct')\n",
    "        return (json.dumps(first), 'fallback_json')\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        s = _find_first_string_in_obj(data)\n",
    "        if s:\n",
    "            return (s, 'direct')\n",
    "        return (json.dumps(data), 'fallback_json')\n",
    "\n",
    "    if isinstance(data, str):\n",
    "        return (data, 'direct')\n",
    "\n",
    "    return (raw, 'raw')\n",
    "\n",
    "# Auto-discover files in prompts/ (handle common variants)\n",
    "repo_root = Path('/Users/rsalvi/Desktop/mccviahat')\n",
    "prompt_dir = repo_root / 'prompts'\n",
    "expected_bases = ['training_n', 'training_e', 'test_n', 'test_e']\n",
    "found_files = []\n",
    "all_jsons = sorted(prompt_dir.glob('*.json')) if prompt_dir.exists() else []\n",
    "for base in expected_bases:\n",
    "    match = None\n",
    "    for p in all_jsons:\n",
    "        if p.stem.lower() == base.lower():\n",
    "            match = p\n",
    "            break\n",
    "    if match is None:\n",
    "        for p in all_jsons:\n",
    "            if p.stem.lower().startswith(base.lower()):\n",
    "                match = p\n",
    "                break\n",
    "    if match is None:\n",
    "        p_try = prompt_dir / (base.capitalize() + '.json')\n",
    "        if p_try.exists():\n",
    "            match = p_try\n",
    "    if match is None:\n",
    "        match = prompt_dir / f\"{base}.json\"\n",
    "    found_files.append(match)\n",
    "\n",
    "print('Prompt files used (in order):')\n",
    "for p in found_files:\n",
    "    print(' -', p)\n",
    "\n",
    "rows = []\n",
    "for p in found_files:\n",
    "    row = {'file': str(p)}\n",
    "    try:\n",
    "        text, method = load_first_prompt(p)\n",
    "        if text is None:\n",
    "            text = ''\n",
    "        n_chars = len(text)\n",
    "        n_words = len(text.split())\n",
    "        n_tokens = count_tokens(text)\n",
    "        row.update({\n",
    "            'n_chars': n_chars,\n",
    "            'n_words': n_words,\n",
    "            'n_tokens': n_tokens,\n",
    "            'method': method,\n",
    "            'preview': text[:300]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        row.update({\n",
    "            'n_chars': None,\n",
    "            'n_words': None,\n",
    "            'n_tokens': None,\n",
    "            'method': 'error',\n",
    "            'preview': f'ERROR: {e}'\n",
    "        })\n",
    "    rows.append(row)\n",
    "\n",
    "cols = ['file', 'method', 'n_chars', 'n_words', 'n_tokens', 'preview']\n",
    "df = pd.DataFrame(rows)[cols]\n",
    "df.index = range(1, len(df) + 1)\n",
    "\n",
    "display(df)\n",
    "df = df.drop(columns = ['method', 'n_chars','n_words', 'preview'])\n",
    "\n",
    "# Save to both repo absolute path and current working dir, and print status\n",
    "out_csv_repo = repo_root / 'analysis' / 'token_counts.csv'\n",
    "out_csv_cwd = Path.cwd() / 'analysis' / 'token_counts.csv'\n",
    "saved_paths = []\n",
    "for out_csv in (out_csv_repo, out_csv_cwd):\n",
    "    try:\n",
    "        out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        saved_paths.append(out_csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save to {out_csv}: {e}\")\n",
    "\n",
    "if saved_paths:\n",
    "    print('Saved counts to:')\n",
    "    for p in saved_paths:\n",
    "        try:\n",
    "            stat = p.stat()\n",
    "            print(f\" - {p}  ({stat.st_size} bytes)\")\n",
    "        except Exception:\n",
    "            print(f\" - {p}  (saved)\")\n",
    "else:\n",
    "    print('No CSVs could be saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae3b74ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_chars'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mccviahat/.mccvenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'n_chars'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m df_plot = df.copy()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mn_chars\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mn_words\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mn_tokens\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     df_plot[c] = pd.to_numeric(\u001b[43mdf_plot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).fillna(\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     11\u001b[39m labels = [Path(f).stem \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m df_plot[\u001b[33m'\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     12\u001b[39m x = np.arange(\u001b[38;5;28mlen\u001b[39m(labels))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mccviahat/.mccvenv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mccviahat/.mccvenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'n_chars'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure numeric columns\n",
    "df_plot = df.copy()\n",
    "for c in ('n_chars','n_words','n_tokens'):\n",
    "    df_plot[c] = pd.to_numeric(df_plot[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "labels = [Path(f).stem for f in df_plot['file']]\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# ---- Color mapping ----\n",
    "def get_color(name):\n",
    "    name = name.lower()\n",
    "    if name.startswith('perm_e'):\n",
    "        return 'red'\n",
    "    elif name.startswith('perm_n'):\n",
    "        return 'blue'\n",
    "    elif name.startswith('test'):\n",
    "        return 'green'\n",
    "    else:\n",
    "        return 'gray'\n",
    "\n",
    "colors = [get_color(label) for label in labels]\n",
    "\n",
    "# ---- Add value labels ----\n",
    "def add_labels(ax, bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2,\n",
    "            height,\n",
    "            f'{int(height)}',\n",
    "            ha='center',\n",
    "            va='bottom'\n",
    "        )\n",
    "\n",
    "# ---------- 1) Characters ----------\n",
    "fig1, ax1 = plt.subplots(figsize=(max(6, len(labels)*1.5), 5))\n",
    "bars1 = ax1.bar(x, df_plot['n_chars'], color=colors)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Character Count')\n",
    "ax1.set_title('Prompt Character Counts')\n",
    "add_labels(ax1, bars1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- 2) Words ----------\n",
    "fig2, ax2 = plt.subplots(figsize=(max(6, len(labels)*1.5), 5))\n",
    "bars2 = ax2.bar(x, df_plot['n_words'], color=colors)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Word Count')\n",
    "ax2.set_title('Prompt Word Counts')\n",
    "add_labels(ax2, bars2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- 3) Tokens ----------\n",
    "fig3, ax3 = plt.subplots(figsize=(max(6, len(labels)*1.5), 5))\n",
    "bars3 = ax3.bar(x, df_plot['n_tokens'], color=colors)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax3.set_ylabel('Token Count')\n",
    "ax3.set_title('Prompt Token Counts')\n",
    "add_labels(ax3, bars3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mccvenv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
